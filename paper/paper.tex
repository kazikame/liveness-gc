\documentclass[10pt]{sigplanconf}
\usepackage{etex}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage{boxedminipage}
\usepackage[T1]{fontenc}
\usepackage[pdf]{pstricks}
\usepackage{epsfig}
\usepackage{multirow}
\usepackage{url}
\usepackage[normalem]{ulem}
\usepackage{schemepgm}
\usepackage{graphicx}
\usepackage{graphpap}
\usepackage{tabularx}
\usepackage {algorithmic}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{pstricks}
\usepackage{pst-text}
\usepackage{pst-node}
\usepackage{pst-tree}
\usepackage{pst-rel-points}
\usepackage{bcprules}
%\usepackage{program}
\input{fh_defs}
\def\drawplusplus#1#2#3{\hbox to 0pt{\hbox to #1{\hfill\vrule height #3 depth
      0pt width #2\hfill\vrule height #3 depth 0pt width #2\hfill
      }}\vbox to #3{\vfill\hrule height #2 depth 0pt width
      #1 \vfill}}
      %Poor man's typography
\def\concat{\mathrel{\drawplusplus {12pt}{0.4pt}{5pt}}}
      %It would be better to specify these in font-relative measures, but it 
      %probably doesn't scale anyway.
\newcommand{\mycomment}[1]{}
\definecolor{Myblue}{rgb}{0.0,0.0,0.5}
\newcommand{\comment}[1]{{\color{Myblue}{\medskip \hrule\medskip
    #1 \medskip \hrule \medskip}}}
\newcommand{\alan}[1]{{\color{red}{\medskip \hrule\medskip
    #1 \medskip \hrule \medskip}}}
\newcommand{\blankout}[1]{}


\newcommand{\scmin} {\mbox{\sf\em in}}
\newcommand{\scmnull}{\mbox{\sf\em null?}}
\newcommand{\scmpair}{\mbox{\sf\em pair?}}
\newcommand{\scmprim}{\ensuremath{\mathsf{+}}}
\newcommand{\sh}[1]{{\colorbox{gray!20}{\framebox{$#1$}}}}
\def\myvec{\mathaccent"017E } % wretched springer mode redefines \vec as bold!
\newcommand{\stk}{\mbox{S}}       % stack
\newcommand{\ID}{\mbox{$\mathbf{ id}$}} % identity function
\newcommand{\bang}{\mbox{\sc bang}}
 
\begin{document}
% --- Author Metadata here ---
\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Liveness-Based Garbage Collection for Lazy Languages}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.
\cmt{{
\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% 1st. author
\alignauthor K. Prasanna Kumar \\
       \affaddr{IIT Bombay,}\\
       \affaddr{Mumbai 400076, India}
       \email{prasanna@cse.iitb.ac.in}
% 2nd. author
\alignauthor Amey Karkare\\
       \affaddr{IIT Kanpur}\\
       \affaddr{Kanpur 208016, India}
       \email{karkare@cse.iitk.ac.in}
% 3rd. author
\alignauthor Amitabha Sanyal \\
       \affaddr{IIT Bombay}\\
       \affaddr{Mumbai 400076, India}\\
       \email{as@cse.iitb.ac.in}
}
}}
\authorinfo{Double Blind Review}{}{}
\maketitle



\begin{abstract}
We  consider  two  ways  to  reduce the  memory  requirement  of  lazy
functional  programming  languages. The  first  is  to modify  garbage
collectors  to  preserve  only  {\em  live} data---a  subset  of  {\em
reachable data}.  This results in an increase in the garbage reclaimed
and  consequently in  fewer  garbage collections.   The  second is  to
eagerly evaluate closures  that are guaranteed to be  evaluated in the
future.  

The  main contribution  of  this  paper is  an  uniform framework  for
obtaining the information for the optimizations mentioned above---{\em
liveness}  and {\em strictness}  analysis. Using  a central  notion of
demand,  we  formulate   a  context-sensitive  liveness  analysis  for
structured  data and  prove  it  correct.  We  then present strictness
as a dual of liveness. We use a  0-CFA-like
conservative   approximation   to   annotate   each   allocation   and
function-call program point  with a finite-state automaton---which the
garbage-collector inspects to  curtail reachability during
marking. The result of the strictness analysis, being necessarily
finite,  can  be directly used to insert code to evaluate closures. 

%As a result,  fewer objects are marked (albeit  with a more expensive
%marker) and then preserved (e.g.\ by a copy phase).

Experiments  confirm  the  expected  performance benefits.  The  early
evaluation   of   closures  decreases   the   memory   demands  of   a
program. Further,  liveness-based collection results in  a increase in
garbage  reclaimed  and  a   consequent  decrease  in  the  number  of
collections, a decrease  in the memory size required  to run programs,
and  reduced  overall  garbage  collection  time  for  a  majority  of
programs.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software  Engineering}{Metrics}[complexity  measures,
  performance measures]

\terms{Theory}

\keywords{ACM proceedings, \LaTeX, text tagging}

By Friday, February 27 2015, 23:59 (UTC-11), submit a full paper of at
most  12 pages (6  pages for  an Experience  Report), in  standard ACM
conference format, including bibliography, figures, and appendices.

\section{Introduction}
\label{sec:intro}

Functional  programming  languages  depend  on  garbage  collector  to
efficiently  reclaim  unused  memory   allocated  by  programs  either
explicitly (for example using constructors) or implicitly (for example
for      closures).       However,      empirical      studies      on
Haskell~\cite{rojemo96lag},  Scheme~\cite{karkare06effectiveness}  and
Java~\cite{shaham02estimating}  programs   have  shown   that  garbage
collectors leave uncollected a lot of memory objects that are not live
(here {\em live}ness  means the object can potentially be  used by the
program at  a later  stage).  Due  to lack of  a suitable  analysis to
distinguish  reachable  objects  from live  objects.  current  garbage
collectors conservatively approximate the  liveness of heap objects by
their reachability from a set of memory locations called the {\em root
  set\/} resulting in unnecessary memory usage.

Languages having lazy  semantics for evaluation put  further demand on
memory as they  require heap allocated closure to be  carried from the
point of occurrence  of an expression to the point  of (first) real use
of  that expression.  Strictness analysis~\cite{some-refs}  statically
determines  the  patterns  of  future usage  of  an  expression,  thus
allowing some  of the  closures to  be evaluated at  the point  of the
occurrence of the corresponding expression.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% MOTIVATING EXAMPLE
\newcommand{\nilfigure}
{\scalebox{0.75}{
\psset{unit=1mm,nodesep=0mm,labelsep=0.5mm}
\begin{pspicture}(0,0)(1,1)
%\psgrid[xunit=1cm,yunit=1cm,gridwidth=.2pt,subgridwidth=.1pt,subgriddiv=5,subgridcolor=gray,gridcolor=blue](0,0)(1,1)
\putnode{start}{origin}{0}{0}{}
\putnode{stop}{origin}{10}{10}{}
\ncline[offsetB=0,nodesepB=0,linewidth=.7]{-}{start}{stop} %here
\end{pspicture}
}}


\begin{figure*}[t!]
%%%%{\color{Myblue}
\begin{picture}(100,130)(0,-90)
%  \begin{center}
    \begin{tabular}{cc}
\begin{boxedminipage}{.5\textwidth}
      {\sf
	\renewcommand{\arraystretch}{1}{
	  \begin{uprogram}
	  \UFL\ \hspace*{-.31\TAL} (\DEFINE\ (\append\  \lista\ \listb)
	  \UNL{0}  (\SIF~(\NULLQ \ \lista)
	       \listb
	  \UNL{1}      (\CONS\ (\CAR\  \lista)
%          \UNL{2}          (\CAR\  \lista)
	  \UNL{2}\;\;\;\;\;          (\append\ (\CDR\  \lista)
          \listb))))
          \UNL{0}
	  \UNL{0} \hspace*{-.49\TAL} (\LET\ \pz  $\leftarrow$(\CONS\ (\CONS\ $4$ (\CONS\ $5$ \NIL))
	  \UNL{3}\ \ \ \  (\CONS\ $6$ \NIL)) \IN
	  \UNL{0} (\LET\ \py  $\leftarrow$ (\CONS\ $3$ \NIL) \IN
	  \UNL{1}   (\LET\ \pw $\leftarrow$ (\append\ \py\  \pz)\ \IN
	  \UNL{1}               $\,\,\,\,\,\,\,\,\pi$:(\CAR\ (\CDR\ \pw)))))
	\end{uprogram}
      }} 
\end{boxedminipage}
      &
      \raisebox{-25mm}{\scalebox{.75}{
	%%%%%%%%%%%%%%%%%%%%%Uday's stuff%%%%%%%%%%%%%%%%%%%%%%%%%
      \psset{unit=1mm}
      \psset{linewidth=.3mm}
      \begin{pspicture}(0,-5)(70,60)
	%\psframe(0,0)(73,60)
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\putnode{o}{origin}{13}{50}{\TwoCells{o1}{o2}}
	\putnode{a}{o}{-10}{-15}{\psframebox{3}}
%	\putnode{b}{o}{10}{-15}{\psframebox[linestyle=none,framesep=.5]{\NIL}}
	\ncline[offsetB=-.5,nodesepB=.1]{*->}{o1}{a}
	%\aput[-3.5](.5){\scalebox{1.2}{\psframebox[framesep=.2,linestyle=none,fillstyle=solid,
	%      fillcolor=white]{$\times$}}}
        \putnode{b}{o}{0}{-3}{\psframebox[linestyle=none,framesep=.5]{\scalebox{.63}{\nilfigure}}}
%	\ncline[offsetB=-.5,nodesepB=.1]{*->}{o2}{b}
	%\ncline[offsetB=-.5,nodesepB=.1]{->}{o2}{b}
	\putnode{y}{o}{-14}{8}{\psframebox[linestyle=none,framesep=.5]{y}}
	\nccurve[nodesepB=-.2,angleA=330,angleB=120]{->}{y}{o}
	\aput[-3.5](.5){\scalebox{1.2}{\psframebox[framesep=.2,linestyle=none,fillstyle=solid,
		  fillcolor=white]{$\times$}}}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\putnode{c}{o}{25}{0}{\TwoCells{c1}{c2}}
	\putnode{d}{c}{10}{-10}{\TwoCells{d1}{d2}}
	\putnode{e}{d}{-13}{-12}{\TwoCells{e1}{e2}}
	\putnode{f}{d}{13}{-12}{\TwoCells{f1}{f2}}
	\ncline[nodesepB=-.5]{*->}{c2}{d}
	\ncline[nodesepB=-.5,linewidth=.7]{->}{c2}{d}
	\nccurve[ncurv=1,angleA=270,angleB=330]{*->}{c1}{a}
	\aput[-3.5](.2){\scalebox{1.2}{\psframebox[framesep=.2,linestyle=none,fillstyle=solid,
	      fillcolor=white]{$\times$}}}
	\nccurve[nodesepB=-.5,angleA=240,angleB=70]{*->}{d1}{e}
	\nccurve[nodesepB=-.5,angleA=240,angleB=70,linewidth=.7]{->}{d1}{e}
	\nccurve[nodesepB=-.5,angleA=300,angleB=110]{*->}{d2}{f}
	\aput[-3.5](.5){\scalebox{1.2}{\psframebox[framesep=.2,linestyle=none,fillstyle=solid,
	      fillcolor=white]{$\times$}}}
	\putnode{w}{c}{-8}{8}{\psframebox[linestyle=none,framesep=.2]{w}}
	\putnode{ww}{c}{15}{8}{\psframebox[linestyle=none,framesep=.2]{z}}
	\nccurve[nodesepB=-.2,angleA=330,angleB=120,linewidth=.7]{->}{w}{c}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\putnode{g}{e}{-8}{-12}{\psframebox{4}}
	\putnode{h}{e}{8}{-14}{\TwoCells{h1}{h2}}
	\putnode{i}{f}{-8}{-11}{\psframebox{6}}
%	\putnode{j}{f}{8}{-11}{\psframebox[linestyle=none,framesep=.5]{\NIL}}
	\ncline[offsetB=-.5,nodesepB=.1]{*-}{e1}{e1}
	\ncline[linestyle=dashed,offsetB=-.5,nodesepB=.1,linewidth=.7]{->}{e1}{g}
        %here
        \putnode{j1}{f}{0}{-3}{\psframebox[linestyle=none,framesep=0]{\scalebox{.63}{\nilfigure}}}
        \putnode{j2}{h}{0}{-3}{\psframebox[linestyle=none,framesep=.5]{\scalebox{.63}{\nilfigure}}}

%        \aput[-3.2](.6){\scalebox{1.2}{\psframebox[framesep=.1,linestyle=none,fillstyle=solid,
%	      fillcolor=white]{$\times$}}} %and here
	\ncline[offsetB=-.5,nodesepB=-.3]{*-}{e2}{e2}
	\ncline[linestyle=dashed,offsetB=-.5,nodesepB=.1,linewidth=.7]{->}{e2}{h} 
%	\aput[-3.2](.5){\scalebox{1.2}{\psframebox[framesep=.1,linestyle=none,fillstyle=solid,
%	      fillcolor=white]{$\times$}}} %and here

	\ncline[offsetB=-.5,nodesepB=.1]{*->}{f1}{i}
	\ncline[offsetB=-.5,nodesepB=.1]{*->}{f2}{j}
	\nccurve[nodesepB=-.2,angleA=270,angleB=90]{->}{ww}{d}
	\aput[-3.2](.4){\scalebox{1.2}{\psframebox[framesep=.1,linestyle=none,fillstyle=solid,
	      fillcolor=white]{$\times$}}}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\putnode{k}{h}{-8}{-11}{\psframebox{5}}
%	\putnode{l}{h}{8}{-11}{\psframebox[linestyle=none,framesep=.5]{\NIL}}
	\ncline[offsetB=-.5,nodesepB=.1]{*-}{h1}{h1}
	\ncline[linestyle=dashed,offsetB=-.5,nodesepB=.1,linewidth=.7]{->}{h1}{k}
%	\ncline[offsetB=-.5,nodesepB=.1]{*->}{h2}{l}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      \end{pspicture}}} \\
      (a) Example program.&
      \renewcommand{\arraystretch}{.9}{\begin{tabular}[t]{ll}
	(b) Memory graph at $\pi$. Thick edges denote \\
        {\white (b) }live links. Traversal stops at edges marked\\
        {\white (b) }$\times$  during garbage collection.
      \end{tabular}}
    \end{tabular}
\end{picture}

\kern -3ex

\caption{Example Program and its Memory Graph.}\label{fig:mot-example}    
%  \end{center}
%%%%}\color{Myblue} end
\end{figure*}
We propose the  use of liveness analysis of heap  cells and strictness
analysis  of expressions  to  reduce the  memory  requirement of  lazy
functional  programming languages.   We modify  garbage collectors  to
preserve  only {\em  live} data---a  subset of  {\em reachable  data}.
This results in an increase  in the garbage reclaimed and consequently
in fewer  garbage collections.  Further, we eagerly evaluate closures
that are guaranteed to be evaluated in the future (strict closures).

The main contribution  of this paper is an uniform  framework for {\em
  liveness} and {\em strictness}  analysis to enable the optimizations
mentioned  above. Using  a central  notion of  demand, we  formulate a
context-sensitive liveness  analysis for structured data  and prove it
correct.  We then  present strictness as a dual of  liveness. We use a
0-CFA-like conservative approximation to  annotate each allocation and
function-call program point with  a finite-state automaton---which the
garbage-collector inspects to curtail reachability during marking. The
result of  the strictness analysis,  being necessarily finite,  can be
directly used to insert code to evaluate closures.

We previously proposed an interprocedural liveness analysis to improve
garbage collection first order eager subset of Scheme~\cite{cc-paper}.
The current paper extends the work to handle lazy evaluation semantics
for the same language.

Experiments  confirm  the  expected  performance benefits.  The  early
evaluation   of   closures  decreases   the   memory   demands  of   a
program. Further,  liveness-based collection results in  a increase in
garbage  reclaimed  and  a   consequent  decrease  in  the  number  of
collections, a decrease  in the memory size required  to run programs,
and  reduced  overall  garbage  collection  time  for  a  majority  of
programs.



%------------------------------------------------------------%
\subsubsection{Motivating Example}
\label{sec:motiv}

Figure~\ref{fig:mot-example}(a) shows  an example program.   The label
$\pi$ of an expression $e$  denotes a program point.  During execution
of  the program, it  represents the  instant of  time just  before the
evaluation  of  $e$.  
We  view the  heap  as a graph.  
Nodes in the heap, also  called  ($\CONS$) {\em  cells\/} contain $\CAR$ and $\CDR$ {\em fields}
containing values.  Edges in the graph are {\em references} and
emanate from {\em variables} or fields.
Variable and field values may also be atomic values ($\NIL$, integers etc.)
While it is convenient to box these in diagrams, our presented
analysis treats them as non-heap values.

Figure~\ref{fig:mot-example}(b)  shows the heap at $\pi$.
The edges shown  by thick arrows are those  which are made live by the
program. In addition,  assuming that
the value of any reachable part of the program result may be explored
or printed, the edges marked by thick dashed arrows are also live.
A cell  is  marked and preserved  during  garbage collection,  only  if it  is
reachable from the  root set through a path of  live edges.  All other
cells can be  reclaimed.  Thus if  a garbage collection takes
% place   at    the   time   represented   by   the    heap   shown   in
at $\pi$ with the    heap   shown   in
Figure~\ref{fig:mot-example}(b), only the cells $\pw$ and $(\CDR~ \pw)$, along with $(\CAR~(\CDR~\pw))$ and all cells reachable from it,
will be marked and preserved.






\subsubsection{Organization of the paper}
Section~\ref{sec:defs} gives
the syntax and semantics of
the language used to illustrate our analysis along with basic concepts
and    notations.
% Section~\ref{sec:operational}   describes    the
% operational semantics  of the  language.
Liveness analysis is described in
Section~\ref{sec:liveness} followed by a sketch of a correctness
proof relative to a non-standard semantics.
Section~\ref{sec:computing} shows how to encode liveness as
finite-state automata.
Section~\ref{sec:experiments}   reports   experimental   results and
Section~\ref{sec:lgc-always-better} proves that a liveness based
collector can never do more garbage collections than a reachability
based collector. 
% and Section~\ref{sec:conclusion} concludes the paper.

\section{The target language---syntax and semantics}
\label{sec:defs}
We let $x$, $y$, $z$ range over variables, $f$ over user-functions and
$p$    over    primitive    functions   ($\CONS$,    $\PRIM$    etc.).
Figure~\ref{fig:lang-syntax} describes the  syntax of our language. It
is a first  order language with lazy semantics  and restricts programs
to        be        in        Administrative        Normal        Form
(ANF)~\cite{chakravarty03perspective}  where all actual  parameters to
functions   are   variables.   This   restriction   does  not   affect
expressibility  (and we ignore  it in  examples when  inessential). In
addition, this  form also explicates the creation  of closures through
$\LET$s which are lazy.  A consequence  of lazy $\LET$ is that $x$ can
also occur  in $s$  in $\LET\,\, x  \leftarrow s\,\, \IN\,\,  e$. This
enables  creation of  graph-like structures  in a  pure  language. The
restriction of \LET\ to a single definition is for ease of exposition;
generalization  to  multiple  definitions  does  not  pose  conceptual
difficulties.  We  further restrict each  variable in a program  to be
distinct, so  that no scope shadowing  occurs---this simplifies proofs
of soundness.  The $\RETURN$  and \SIF\ expressions trigger evaluation
of  closures.

The body of the program is the expression denoted by $e_\mainpgm$; for
analysis purposes it is convenient to regard $e_\mainpgm$ as part of a
function definition $(\DEFINE\ ({\tt main})\ e_\mainpgm)$ as in C\@.
We write  $\pi\!:\!e$ to  associate the label  $\pi$ (not part  of the
language syntax) with the program point just before expression $e$.

% \paragraph{Inlining.}
{\color{Myblue}In spite of the ANF  restrictions it is still possible to
  inline non-recursive functions (a fact we use to prove the safety of
  liveness  analysis).  A user-function  call $(\LET\,\,  x \leftarrow
  (f\,y_1\,\ldots\,y_n) \,\, \IN\,\, e)$  to a function defined (after
  renaming  its  formals  and  locals  to be  disjoint  from  existing
  variables) by $(\DEFINE\ (f\ z_1\ \ldots\ z_n)\ e_f)$ is replaced by
  a  sequence of  $\LET$'s  of the  form $z_i\leftarrow  (\ID\,\,y_i)$
  followed by the body $e_f$ but with its $(\RETURN\,\,w)$ expressions
  replaced by $(\LET\,\, x \leftarrow (\ID\,\, w) \,\, \IN\,\, e)$.}

\begin{figure*}[]
\footnotesize
\begin{eqnarray*}
   p \in \mathit{Prog} & ::= & d_1 \ldots d_n \,\, e_\mainpgm
    \hspace{7em} \mbox{\em --- program}\\
    d \in Fdef & ::= & (\DEFINE\,\, (f\,\, x_1 \,\, \ldots \,\,x_n)\,\,
    e) 
    \hspace{1.7em} \mbox{\em --- function definition} \\
e \in \mathit{Expr} & ::= &
\left\{\begin{array}{ll@{\hspace{4em}}l}
       (\SIF\,\, x\,\, e_1\,\, e_2) && \mbox{\em --- conditional} \\ 
       (\LET\,\, x \leftarrow s\,\, \IN\,\, e) && \mbox{\em --- let binding} \\
       (\RETURN\,\, x) && \mbox{\em --- return from function}
    \end{array}\right. \\
s \in \mathit{Application} & ::= &
\left\{\begin{array}{lr@{\hspace{1em}}l}
       k && \mbox{\em --- constant (numeric or $\NIL$)}\\
       (\CONS\,\, x_1\,\, x_2) && \mbox{\em --- constructor} \\ 
       (\CAR\,\, x) &  (\CDR\,\, x) & \mbox{\em --- selectors} \\ 
       (\NULLQ\,\, x) & (\PRIM\,\, x_1\,\, x_2) & \mbox{\em ---  tester and generic arithmetic} \\ 
%        (\NULLQ\,\, x) && \mbox{\em ---  tester} \\ 
       (\ID\,\, x) && \mbox{\em ---  identity function (for inlining)} \\ 
%        (\PRIM\,\, x_1\,\, x_2) && \mbox{\em --- generic arithmetic} \\ 
       \multicolumn{2}{l}{(f\,\, x_1\,\,\ldots\,\, x_n)} 
            & \mbox{\em --- function application} 
    \end{array}\right.
\end{eqnarray*}
  \caption{The syntax of our language}\label{fig:lang-syntax}
\figrule
\normalsize
\end{figure*}


\subsubsection{Semantics}
We now give  a small-step semantics for our  language.  We shall later
augment this semantics so that it enables us to reason about liveness.
We start with the domains used by the semantics:
\[
\begin{array}{rlcl@{\hspace{2em}}l}
\rho: & \mathit{Env} &=&\mathit{Var} \rightarrow \mathit{Loc} & \mbox{-- Environment} \\ 
v:   & \mathit{Val} &=& \mathbb{N} + \{\NIL\} + \mathit{Data \times
  Data}& \mbox{-- Values}\\
c:   & \mathit{Clo} &=& \mathit{(Exp \times Env)}& \mbox{--
  Closures}\\
d: & \mathit{Data} &=&\mathit{Val} + \mathit{Clo} & \mbox{-- Values/Closures} \\ 
\heap: & \mathit{Heap} & =&\mathit{Loc} \rightarrow Data & \mbox{-- Heap}
\end{array}
\]

Here $\mathit{Loc}$ is a countable set  of locations in the heap.  Since
all data objects are boxed, we  model an environment as a mapping from
the set of variables of the program $\mathit{Var}$ to locations in the
heap.  These either contain a value  in WHNF (a number, the empty list
$\NIL$, or  a \CONS\ cell with possibly unevaluated constituents)
or a {\em closure}.   A closure is a pair $(s, \rho)$  in which $s$ is
an  unevaluated application  with  the values  of  its free  variables
given by $\rho$.

The semantics of expressions (and applications) are given by
the  judgment form $\rho,  \stk, \heap,  e \rightarrow  \rho', \stk',
\heap', e'$.  Here \stk\ is a stack of continuation frames represented
as  a list  in the  description of  the semantics.   Each continuation
frame  is of the  form $(\rho,  x, e)$,  where the  location of  $x$ is
updated when the currently evaluated expression reaches
WHNF,  and  $e$  is  the  next  expression  to  be  evaluated  in  the
environment  $\rho$.   The  start  state is  $(\{\},[(\{\},  \mainpgm,
  \HALT)], \{\}, e_\mainpgm)$, and the program terminates successfully
on  reaching   the  halt   state  $(\rho,[\,],  \heap,   \HALT)$  with
$\rho(\mainpgm)$  containing  the final  result.  Note  that since  we
assume that our language is not statically typed, a program with other
than syntactic errors (including those that could have been eliminated
using a  static type system) lead  to {\em stuck  states} i.e.  states
not covered by any rules in the small-step semantics.

The  notation $[\myvec{x} \mapsto  \myvec{\ell}]$ represents
an  environment that maps  variables $x_1,  \ldots, x_n$  to locations
$\ell_1,  \ldots,  \ell_n$.   The  notation  $\heap[\ell  \mapsto  d]$
indicates the  updation of  a heap \heap\  at $\ell$ with  $d$.  $\rho
\oplus \rho'$  represents the  environment $\rho$ shadowed  by $\rho'$
and $\lfloor \rho \rfloor_X$  represents the environment restricted to
the locations in $X$. Finally $FV(s)$ represents the free variables in
the application $s$.

As an example, consider the rules related to the application $(+~x~y)$
involving a strict binary operator.  When both $x$ and $y$ are already
in WHNF  ({\sc prim-whnf}), the  heap is updated  with the sum  of the
arguments  and  the  continuation  gives  the next  expression  to  be
evaluated.   If  either  of  the   arguments  is  not  in  WHNF  ({\sc
  prim-1-clo} and {\sc prim-2-clo}), it  is sent for evaluation, and a
continuation marks that the evaluation  of $(+~x~y)$ has to be resumed
after the argument is evaluated.


\begin{figure*}[t!]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Premise & Transition & Rule name \\
\hline
\hline
          & $\rho, (\rho', x, e)\!:\!S, H, \kappa
  \rightsquigarrow \rho', S, H[\rho'(x) \mapsto \kappa], e$    &  \sc{const} \\
\hline
          & \shortstack[c]{$\rho, (\rho', z, e)\!:\!S, H, (\CONS~x~y)  \rightsquigarrow
$ \\  $\rho', S, H[z \mapsto (H(\rho(x)),H(\rho(y)))], e$}     &  \sc{cons} \\
\hline
$H(\rho(x)) \mbox{ is } (d_1, d_2)$ & $\rho, (\rho', z, e)\!:\!S, H,
(\CAR~x)  \rightsquigarrow \rho', S, H[\rho(z) \mapsto d_1], e$      &  \sc{car-whnf} \\
\hline
$H(\rho(x)) \mbox{ is } (e, \rho')$ & $\rho, S, H, (\CAR~x)  \rightsquigarrow
\rho'\oplus\rho, (\rho, x, (\CAR~x))\!:\!S, H, e$      &  \sc{car-clo} \\
\hline
$H(\rho(x)), H(\rho(y)) \in \mathbb{N}$
 & \shortstack[c]{$\rho, (\rho', z, e)\!:\!S, H, (+~x~y)  \rightsquigarrow$ \\
$\rho', S, H[\rho(z) \mapsto H(\rho(x)) + H(\rho(y))], e$}      &  \sc{prim-whnf} \\
\hline
$H(\rho(x)) \mbox{ is } (s, \rho')$ & $\rho, S, H, (+~x~y)  \rightsquigarrow
\rho'\oplus\rho, (\rho, x, (+~x~y))\!:\!S, H, e$      &  \sc{prim-1-clo} \\
\hline
$H(\rho(y)) \mbox{ is } (s, \rho')$ & $\rho, S, H, (+~x~y)  \rightsquigarrow
\rho'\oplus\rho, (\rho, x, (+~x~y))\!:\!S, H, e$      &  \sc{prim-2-clo} \\
\hline
\shortstack[c]{$\mathit{f}~\mbox{defined as}$ \\ $~(\DEFINE~(f~\myvec{y})~e_{\mathit{f}})$}  & $\rho, S, H, (f~\myvec{x})  \rightsquigarrow
[\myvec{y} \mapsto \rho(\myvec{x})], S, H, e_{\mathit{f}}$      &  \sc{funcall} \\
\hline
$\ell$ is a new location& \shortstack[c]{$\rho, S, H, (\LET~x\leftarrow s~\IN~e)
  \rightsquigarrow$ \\
$[x \mapsto \ell]\oplus\rho, S, H[\ell \mapsto (s, (x \mapsto
  \ell)\oplus\lfloor \rho\rfloor_{FV(S)\setminus\{x\}})], e$} & \sc{let} \\ 
\hline
$H(\rho(x)) \ne 0$ & $\rho, S, H, (\SIF~x~e_1~e_2)   \rightsquigarrow
\rho, S, H,  e_1$ & \sc{if-true} \\ 
\hline
$H(\rho(x)) = 0$ & $\rho, S, H, (\SIF~x~e_1~e_2)   \rightsquigarrow
\rho, S, H,  e_2$ & \sc{if-false} \\ 
\hline
$H(\rho(x)) = (e,\rho')$ & \shortstack[c]{$\rho, S, H,
  (\SIF~x~e_1~e_2)   \rightsquigarrow$ \\ 
$\rho'\oplus\rho, (\rho, x, (\SIF~x~e_1~e_2))\!:\!S, H,  e$} & \sc{if-clo} \\ 
\hline
\shortstack[c]{$H(\rho(x))~\mbox{is}$ \\$\mbox{whnf with value}~v$}& $\rho, (\rho', z, e)\!:\!S, H,
(\RETURN~x)  \rightsquigarrow \rho', S, H[\rho(z) \mapsto v], e$ & \sc{return-whnf}\\   
\hline
$H(\rho(x)) = (e,\rho')$ & \shortstack[c]{$\rho, S, H, (\RETURN~x)
  \rightsquigarrow$ \\
$\rho'\oplus\rho,~ (\rho, x, (\RETURN~x))\!:\!S, H,  e$} & \sc{return-coo} \\
\hline
\end{tabular}
\caption{A small-step semantics for the language}\label{fig:lang-semantics}
\end{center}
\end{figure*}


%==============================================================
\renewcommand{\pp}[2]{\ensuremath{#1\!\!:\!#2}} % prog point



\section{Liveness}\label{sec:liveness}

A variable is {\em live} if  there is a possibility of its value being
used  in future computation  and dead  if it  is definitely  not used.
Heap-allocated data needs a richer model of liveness which talks about
liveness  of  pointers  including  fields  of  $\CONS$  cells.   Using
$\acar$, $\acdr$  to represent access using $\CAR$  and $\CDR$ fields,
the  liveness  of the  structure  reachable  from  a variable  can  be
represented by a set of {\em access paths} i.e.  prefix-closed strings
from $\{\acar,\acdr\}^\ast$.   As an  example, if $x$  is a  list with
liveness      $\{\epsilon,     \acdr,      \acdr\acar,     \acdr\acdr,
\acdr\acdr\acar\}$, then future computations  can only refer up to the
second and  third members of $x$.   A {\em liveness  environment} is a
mapping from variables to subsets of $\{\acar,\acdr\}^\ast$, but often
expressed as  a set, for example by  writing $\{x.\epsilon, x.\acdr, x.\acdr\acdr, 
y.\epsilon\}$               instead               of               $[x
  \mapsto\{\epsilon,\acdr,\acdr\acdr\},     y\mapsto\{\epsilon\},
  z\mapsto\{\}]$.   In  this   notation,   $x  \mapsto   \{\epsilon\}$
represents access using $x$ itself and $x \mapsto \{\}$ indicates that
$x$ is dead.  We associate  a liveness environment with program points
$\pi$.  The liveness at $\pi:e$  is the liveness just before executing
$e$.


A  notion related  to  liveness is  {\em  demand}.  The  demand on  an
expression  $e$  is again  a  set  of  access paths---that  subset  of
$\{\acar,\acdr\}^\ast$ which  the context of $e$ may  explore of $e$'s
result.   To see  the need  for demands,  consider the  let expression
$\pi:(\LET~x\leftarrow (\CDR~y)~\IN~ \pi':\RETURN~x)$. Assume that the
context of  this expression produces the liveness  $[x \mapsto \lbrace
  \epsilon, \acar  \rbrace]$ at $\pi'$.   Due to the  \LET\ definition
which  binds $x$  to $(\CDR~y)$,  the liveness  of $x$  at  $\pi'$ now
becomes  the  demand on  $(\CDR~y)$.   This,  in  turn, generates  the
liveness $\lbrace y.\epsilon,  y.\acdr, y.\acdr\acar \rbrace$ at $\pi$
(the set of $y$-rooted accesses required to explore $\lbrace \epsilon,
\acar  \rbrace$  paths  of  the  result  of  $(\CDR~y)$)\footnote{The
  classical analogue  is strong liveness  analysis, where $y$  and $z$
  have  a  liveness  of  $\lbrace\epsilon\rbrace$  at  the  entry  $n:
  x:=y+z$,    if   and    only   if    $x$   has    a    liveness   of
  $\lbrace\epsilon\rbrace$ at  exit of  $n$.  In our  terminology, the
  liveness of $x$  at exit from $n$ becomes the  demand on $y+z$. This
  generates the  liveness $\lbrace y.\epsilon,  z.\epsilon \rbrace$ at
  the entry of $n$.}.
%% Exploring $\lbrace \epsilon, \acar \rbrace$ of the
%% result of $(\CDR~y)$ first requires access using $y$ ( and the \CDR\ field of the cons cell pointed by
%% $y$.
Note that  liveness refers to  access using variables and  fields, and
not  to $\CONS$  cells (i.e.\  to edges  in the  memory graph,  not to
locations themselves).

We use $\sigma$  to range over demands, $\alpha$  to range over access
paths  and $\Lv$ to  range over  liveness environments.   The notation
$\sigma_1\sigma_2$  denotes  the  set $\lbrace  \alpha_1\alpha_2  \mid
\alpha_1 \in \sigma_1, \alpha_2  \in \sigma_2\rbrace$.  Often we shall
abuse notation to  juxtapose an edge label and a  set of access paths:
$\acar\sigma$ is a shorthand for $\lbrace\acar\rbrace\sigma$. A more
elaborate explanation of these notions appear in \cite{asati14lgc}

%% Finally, we use $\Lfonly$  to range over {\em demand transformers}.
%% These transform  demands on  a function call  into demands  for its
%% formal  parameters:   given  a   user  function  $f$,   defined  by
%% $(\DEFINE\ (f\  x_1\ \ldots\ x_n)\  \ e_f)$ and called  with demand
%% $\sigma$,  then $\Lf{f}{i}{\sigma}$  is  the liveness  of $x_i$  at
%% $e_f$.

\subsection{Liveness Analysis for lazy languages}

Figure~\ref{fig:live-judge}  describes  our  analysis  which  has  two
parts. The function $\mathit{ref}$,  when given an application $s$ and
a demand $\sigma$, returns  the incremental liveness generated for the
free  variables   of  $s$  due  to  the   application.   The  function
$\mathcal{L}$  uses   $\mathit{ref}$  to  propagate   liveness  across
expressions.

 In each  rule defining $\mathit{ref}$, the  null demand ($\emptyset$)
 generates no  liveness.  Notice that this is  different from liveness
 of  eager  languages,  where,   for  instance,  (\CDR~$x$)  would  be
 evaluated even for the null  demand, and this would require an access
 using  $x$.   A  non-null   demand  of  $\sigma$  on  (\CDR~$x$),  is
 transformed  to  the  liveness  $\{x.\epsilon, x.\acdr\sigma\}$.   In  an
 opposite  sense, the  demand of  $\acdr\sigma$ on  (\CONS~$y$~$z$) is
 transformed to  the demand  $\sigma$ on $z$.   Note that  \CONS\ does
 not, by itself, dereference  its arguments. The rules for (\PRIM~x~y)
 and (\NULLQ~x) are on similar lines. Constants generate no liveness.


For  the  case  of a  user-function  call  we  use a  third  parameter
$\Lfonly$  that  represents the  summaries  of  all  functions in  the
program. $\Lfonly_f$ (the component of $\Lfonly$ for a specific
function $f$),  expresses how the  demand $\sigma$ on the result of
a call to $f$ is transformed  into the liveness of its parameters at the
beginning of the call.  $\Lfonly$  is determined by the judgement form
$\mathit{Prog} \len \Lfonly$ using inference rule ({\sc live-define}).
This  rule  describes the  fixed-point  property  to  be satisfied  by
$\Lfonly$, namely, the demand transformation assumed for each function
in  the  program should  be  the  same  as the  demand  transformation
calculated    from    their   bodies.    As    we    shall   see    in
Section~\ref{sec:grammar-formulation},  the  least solution  satisfying
the  rule  is obtained  by  converting  the  rule into  an  equivalent
grammar.  The least solution also  ensures that the greatest amount of
garbage is collected.
  


%%   Analogously to classical liveness being computed as a solution of
%% dataflow   equations,  we   require,  via   inference   rule  ({\sc
%% live-define}), $\Lfonly$ to  satisfy the fixed-point property that:
%% when we  assume $\Lfonly$ to  be the family of  demand transformers
%% for the program then the  calculated liveness of each function body
%% $\mathcal{L}(e_f,\sigma,\Lfonly)$    agrees   with    the   assumed
%% $\Lfonly$.   As  usual,  there  are  often  multiple  solutions  to
%% $\Lfonly$; all are  safe (see Section~\ref{sec:correctness}) but we
%% prefer  the least  one  as  giving the  least  liveness subject  to
%% safety---and hence greatest amount of garbage collected.


We next  describe the function $\mathcal{L}$  that propagates liveness
across  expressions.   This brings  us  to  the  second way  in  which
liveness analysis for lazy languages differ from eager languages---the
point  where  an  expression   gets  evaluated  cannot  be  statically
determined.  To  deal with this, we introduce  flow insensitivity into
our  analysis.  



%%%%%%%%%%%%%%%%%%%%%%

% Push this to a later point


%% Unlike eager languages, a variable may be bound to an expression
%%   that is not fully evaluated. i.e. a closure.


%% To  deal with the  first issue,  we apply  the results  of liveness
%% analysis only to fully evaluated data.  If the marking phase during
%% garbage collection leads to a closure, and the closure is not dead,
%% we  mark  the  entire   reachable  memory  under  the  closure  for
%% collection.   A  better scheme  would  be  to  garbage collect  the
%% closure based on  the liveness at the point  of its creation.  This
%% is sound because our  language is statically scoped.  However, this
%% is  work  in progress,  and  the  method  described in  this  paper
%% switches over to reachability while collecting closures.

%%%%%%%%%%%%%%%%%%%%%%%%


\renewcommand{\arraystretch}{1}{
	  \begin{uprogram}
	  \UNL{0}\hspace*{-.5cm} (\DEFINE\ (\pf~\pa)
	  \UNL{1}\hspace*{-.5cm}  $\pi_1\!\!:\, $(\LET\ \px\ $\leftarrow $\ (\CONS~1~\px) \IN
	  \UNL{2}\hspace*{-.5cm}      $\pi_2\!\!:\, $(\LET~\py\ $\leftarrow $\ (\CDR~\px) \IN  
          \UNL{3}\hspace*{-.5cm} \hspace*{.05cm}     $\pi_3\!\!:\,
          $(\LET\ \pz\  $\leftarrow$\   (\NULLQ~\pa) \IN
	  \UNL{4}\hspace*{-.45cm}      $\pi_4\!\!:\,
          $(\SIF\ $\pi_5\!\!:\,$ \pz\ ~$\pi_6\!\!:\,$ (\LET~\ww\  $\leftarrow$  (\take~5~\px) \IN
	  \UNL{5}\hspace*{.45cm}     $\pi_7\!\!:\, $(\LET~\pu\  $\leftarrow$  (\CDR~\pw)  \IN
	  \UNL{6}\hspace*{.45cm}  $\pi_8\!\!:\,(\RETURN_1~\pu)$))
          \UNL{5}\hspace*{-.45cm}  $\pi_9\!\!:\, (\RETURN_2~\py)$)))))
	\end{uprogram}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\medskip



Consider  an analysis of  the body  of $\pf$  with a  demand $\sigma$.
Clearly, this is also the demand on the return values $u$ and $y$
giving the liveness  at  the  program points  $\pi_7$  and $\pi_8$  as
$\lbrace  \pu.\sigma \rbrace$ and  $\{\py.\sigma\}$.  The  liveness at
$\pi_7$  and  $\pi_8$  are  propagated  backwards  as  in  traditional
liveness analysis.

Since   \pu\  is  $(\CDR~   \pw)$,  the   liveness  of   $\sigma$  for
\pu\ translates  into a demand  of $\sigma$ on $(\CDR~\pw)$,  which in
turn  generates  a  liveness  of $\{\pw.\epsilon,  ~\pw.1\sigma\}$  at
$\pi_7$.  The liveness of \pu\ should be killed at $\pi_7$ since it is
not in the scope of \pu.  However, this does not cause any imprecision
in the way  of the GC marking more  cells as live, since \pu\  is yet to
come into existence at $\pi_7$  and its liveness will not be consulted
by the garbage collector at this point.
%==============================================================
\begin{figure*}[t]  
\begin{eqnarray*}
\mathit{ref\/}(\kappa,\sigma,\Lfonly)
          &=& \{\,\} \mbox{, for $\kappa$ a constant, including $\NIL$}\\
\mathit{ref\/}((\CONS~x~y),\sigma,\Lfonly)
          &=& \{x.\alpha \mid \acar\alpha \in \sigma\} \cup \{y.\alpha \mid \acdr\alpha \in \sigma\} \\
\mathit{ref\/}((\CAR~x),\sigma,\Lfonly)
          &=&    \begin{array}{l l}
                    \{x.\epsilon\} \cup \{x.\acar\alpha \mid \alpha \in
\sigma\}, & \mbox{if}~\sigma \ne \emptyset\\
                    \emptyset  & \mbox{otherwise}
                 \end{array} \\
\mathit{ref\/}((\CDR~x),\sigma,\Lfonly)
          &=&    \begin{array}{l l}
                    \{x.\epsilon\} \cup \{x.\acdr\alpha \mid \alpha \in
\sigma\}, & \mbox{if}~\sigma \ne \emptyset\\
                    \emptyset  & \mbox{otherwise}
                 \end{array} \\
\mathit{ref\/}((\PRIM~x~y),\sigma,\Lfonly)
          &=&    \begin{array}{l l}
                    \{x.\epsilon, y.\epsilon\},  & \mbox{if}~\sigma \ne \emptyset\\
                    \emptyset  & \mbox{otherwise}
                 \end{array} \\
\mathit{ref\/}((\NULLQ~x),\sigma,\Lfonly)
          &=&    \begin{array}{l l}
                    \{x.\epsilon\},  & \mbox{if}~\sigma \ne \emptyset\\
                    \emptyset  & \mbox{otherwise}
                 \end{array} \\
\mathit{ref\/}((f~\myvec{x}),\sigma,\Lfonly)
%          &=& \bigcup_{i=1}^n y_i.\Lf{f}{i}{\sigma}
          &=&  \begin{array}{@{}l}  % to discourage \displaystyle
               \bigcup_{i=1}^n x_i.\Lf{f}{i}{\sigma}
               \end{array}
%          &=& \bigcup \{y_i.\Lf{f}{i}{\sigma} \mid i=1,\ldots, n\}
\\[1ex]
\mathcal{L}((\RETURN~x),\sigma,\Lfonly) &=& \{l \mapsto x.\sigma\}, \makebox[0mm]{\hspace*{3cm} where $l$ is a new label} \\
\mathcal{L}((\SIF~x~e_1~e_2),\sigma,\Lfonly) &=&
        \begin{array}{l l}
                    \mathcal{L}(e_1,\sigma,\Lfonly) \uplus
        \mathcal{L}(e_2,\sigma,\Lfonly) \uplus
        \{l \mapsto  \{x.\epsilon\}\},  & \mbox{if}~\sigma \ne \emptyset\\
        \emptyset_{\cal{M}?}  & \mbox{otherwise}
                 \end{array} \\
 \makebox[0mm]{\hspace*{3.8cm} where $l$ is a new label}\\
\mathcal{L}(\LET~x \leftarrow~s~\IN~e),\sigma,\Lfonly) &=&
        \{ l \mapsto \Ldonly_{x \leftarrow s}(\Lv(x)) \mid l \mapsto \Lv
        \in \mathcal{M}\}
\mbox{ where } \mathcal{M} = \mathcal{L}(e,\sigma,\Lfonly)\\
\Ldonly_{x \leftarrow s} &=& \Lfonly_f, \mbox{where}~f~\mbox{is a new function}\\
 \makebox[0mm]{\hspace*{7cm}   
 $(\DEFINE~(f\,x_1\,x_2\, \ldots \, x_n)~(\SIF\,*~x~s[(f\,x_1\,
           x_2\, \ldots\, x_n)/x]))$,} \\
 \makebox[0mm]{\hspace*{5.5cm} and 
     $(\ x_1\, \ldots\, x_n)$ are the variables in $s$}
\end{eqnarray*}
\begin{minipage}{0.85\textwidth}
\infrule[live-define]
        {\mathcal{L}(e_f,\sigma,\Lfonly) = 
           \bigcup_{i=1}^n z_i.\Lf{f}{i}{\sigma}
              \mbox{ for each $f$ and $\sigma$}
        }
        { d_1 \ldots d_k \len \Lfonly
\\ \makebox[0mm]{where
     $(\DEFINE\ (f\ z_1\ \ldots\ z_n)\ \ e_f)$ is a member of $d_1 \ldots d_k$}}
\end{minipage}
  \caption{Liveness equations and judgement rule}\label{fig:live-judge}
\end{figure*}
%======================================================================================
In an eager language, \pw\ would not have been live after $\pi_7$, the
point of  its last  use. In a  lazy language, however,  the definition
$\pu  \leftarrow (\CDR~\pw)$,  does  not result  in  an evaluation  of
$(\CDR~\pw)$; instead  a closure is created.   The evaluation actually
takes place while evaluating  $(\RETURN~\pu)$. Thus it is necessary to
record the liveness  of $\pw$ at the program  point $\pi_8$, indeed at
every program  point from $\pi_8$ up  to the beginning  of the program
(since  we do  not kill  liveness).  We  thus regard  the body  of the
function as  a tree and consider paths  from the root of  this tree to
program  points  which  trigger  a evaluation---\SIF\  conditions  and
\RETURN\  expressions.  We  call such  paths {\em  e-paths}.   For the
program shown, there are three such paths $EP_1 = \pi_1, \pi_2, \pi_3,
\pi_4,  \pi_5$, $EP_2  =  \pi_1, \pi_2,  \pi_3,  \pi_4, \pi_6,  \pi_7,
\pi_8$, and $EP_3 = \pi_1, \pi_2, \pi_3, \pi_4, \pi_9$.

The analysis  consists of  two maps: The  map $\cal{M}$ maps  a return
path to a common liveness environment, and a second map $\cal{P}$ maps
a program  point to the set of  e-paths on which  the point lies.
If a  program  point happens to fall  on more than one  such path, then
the  liveness environment of  the program  point is  the variable-wise
union of  the liveness environments  of the individual paths.   In the
example program, ${\cal M}(EP_1)= \ldots$, ${\cal M}(EP_2)=\ldots$ and
${\cal M}(EP_3)=  \ldots$.  Since  ${\cal P}(pi_4)$ is  $\lbrace EP_1,
EP_2, EP_3 \rbrace$, the liveness  of $pi_4$ is \ldots.  In summary,
our propagation of liveness is flow-insensitive but path-sensitive.
In the sequel
we  shall  describe  how  to  obtain $\cal{M}$.   The  formulation  of
$\cal{P}$ is easy and we do not elaborate it any further.

Consider  the $\mathcal{L}$-rules for  {\LET}, {\SIF},  and {\RETURN}.
The  expression $\pi:(\RETURN~x)$  with  a demand  $\sigma$ forces  an
evaluation  of  $x$  and  hence  a  new  map  ${\cal  M}=[\pi  \mapsto
  \{x.\sigma\}] $  needs to  be created.  The  ${\cal M}$-map  for the
expression $(\SIF~\pi:x~e_1~e_2)$  is a pointwise-union  of the ${\cal
  M}$-maps of $e_1$ and $e_2$.   In addition, since the condition also
triggers an evaluation of  $x$, the map $[\pi \mapsto \{x.\epsilon\}]$
is created and added to  the union.  Also notice that the consequences
of  laziness---the entire  expression including  the condition  is not
evaluated if  the demand  on it is  $\emptyset$.  This results  in the
empty map denoted by $\emptyset_{\cal{M}}$.

  
 The  {\LET} rule  has  an elegant  formulation.   Recollect that  our
 language permits lazy \LET~s whose definitions can be recursive Thus,
 in the expression $\LET~x  \leftarrow~s~\IN~e$, $x$ can occur in $s$.
 We  model the  definition $x  \leftarrow~s$ as  a  possibly recursive
 function which captures an  arbitrary number of ``unrollings'' of the
 definition.  We pass  to this function the demand  arising out of the
 liveness   of  $x$   at   the   beginning  of   $e$,   and  let   the
 \Lfonly\ abstraction derive the liveness on the variables of $s$.


\mycomment{The function  $\mathcal{L}$ now  gives  the  (total)  liveness of  an
expression $e$.   The cases $\RETURN$ and  $\SIF$ are straightforward,
but note the liveness $x.\epsilon$  generated by the latter.  The case
$(\LET\   z\leftarrow   s\  \IN\   e')$   resembles  a   three-address
instruction:  the liveness  of $e$  is given  by taking  the liveness,
$\Lv$, of $e'$, killing any liveness of $z$ and adding any incremental
liveness from  $s$.  The main subtlety  is how the liveness  of $z$ in
$\Lv$  is converted  to a  demand  $\Lv(z)$ to  be placed  on $s$  via
$\mathit{ref}(s,\Lv(z),\Lfonly)$.

%%%%%%\marginpar{Say $\mathcal{L}$ is monotonic?}

% \end{itemize}

We make three observations: firstly the rule ({\sc live-define}) has a
least  solution  as  $\mathcal{L}(\cdot)$  is monotonic  in  $\sigma$;
secondly  that  ({\sc  live-define})   resembles  the  rule  for  type
inference of mutually recursive  function definitions, and thirdly the
asymmetry of  demand and liveness (compared to  post- and pre-liveness
classically) is due to the functional formulation here.
}%mycomment

Section~\ref{sec:computing}   shows   how   the  demand   transformers
$\Lfonly$  for  a  program  (representing  a  fully  context-sensitive
analysis) can  be safely  approximated, for each  function, by  a {\em
  procedure summary} (unifying the  contexts in the style of 0-CFA)\@.
The  summary consists  of a  pair  of a  single demand  and, for  this
demand, the corresponding  tuple of demands the function  makes on its
arguments.

%\comment{

\section{Generating Liveness Equations}
\begin{figure*}[t!]
\begin{picture}(100,130)(0,-90)
  \begin{tabular}{cc}
    \begin{boxedminipage}{.5\textwidth}
      {\sf
        \renewcommand{\arraystretch}{1}{
          \begin{uprogram}
            \UNL{1} (\DEFINE\ (\length~\xl)
            \UNL{2}  $\pi_1\!\!:\, $(\LET\ \px\ $\leftarrow $\ (\NULLQ~\xl) \IN
            \UNL{3} \hspace*{.05cm} $\pi_2\!\!:\,$(\SIF\ $\pi_3\!\!:\,$ \px
            \UNL{4} \hspace*{1.15cm} $\pi_4\!\!:\, (\RETURN_1~0)$
            \UNL{4} \hspace*{1.15cm}    $\pi_5\!\!:\, $(\LET~\pu\  $\leftarrow$  (\CDR~\xl)  \IN
            \UNL{5} \hspace*{1.15cm}   $\pi_6\!\!:\, $(\LET~\py\  $\leftarrow$  (\length~\pu)  \IN
            \UNL{6} \hspace*{1.15cm} $\pi_7\!\!:\, (\RETURN_2~(1~+~\py))$)))))
        \end{uprogram}}
        \renewcommand{\arraystretch}{1}{
	  \begin{uprogram}
	  \UNL{1} $\pi_\mainpgm\!\!:\, $(\LET\  \pa\  $\leftarrow$ \ldots  \IN
	  \UNL{2}   \hspace*{.78cm}              (\LET\ \pb\  $\leftarrow$  \ldots \IN 
          \UNL{3}   \hspace*{.78cm}    $\pi_8\!\!:\, $(\LET\ \pw\  $\leftarrow$  (\length\ \py) \IN~$\pi_{9}\!\!:\,$ (\RETURN\ \pw)))))))
\end{uprogram}}
        } 
    \end{boxedminipage}
    & 
    \begin{boxedminipage}{.5\textwidth}
      {\sf
        \begin{tabular}{lc}
        $\cal{M} = $ 
            \begin{tabular}{lc}            
              $[$
              $\pi_{\mbox{7}} \mapsto \lbrace \py.\epsilon, \pu.\Lf{\length}{\mbox{1}}{\epsilon}, \
              \xl.\mbox{1}\Lf{\length}{\acdr}{\epsilon}, \xl.\epsilon  \rbrace ,$ \\ 
              $\pi_{\mbox{4}} \mapsto \lbrace \rbrace , $\\
              $\pi_{\mbox{3}} \mapsto \lbrace \px.\epsilon, \xl.\epsilon \rbrace $  \\
              $]$
            \end{tabular} \\
            $\cal{P} = [$
              \begin{tabular}{lc}
              $\pi_{\mbox{1}} \mapsto \lbrace \pi_{\mbox{3}},\pi_{\mbox{4}}, \pi_{\mbox{7}} \rbrace, $ \
              $ \pi_{\mbox{2}} \mapsto \lbrace \pi_{\mbox{3}},\pi_{\mbox{4}}, \pi_{\mbox{7}} \rbrace, $ \\
              $ \pi_{\mbox{3}} \mapsto \lbrace \pi_{\mbox{3}} \rbrace, $ \
              $ \pi_{\mbox{4}} \mapsto \lbrace \pi_{\mbox{4}} \rbrace, $ \
              $ \pi_{\mbox{5}} \mapsto \lbrace \pi_{\mbox{7}} \rbrace, $ \\
              $ \pi_{\mbox{6}} \mapsto \lbrace \pi_{\mbox{7}} \rbrace, $ \
              $ \pi_{\mbox{7}} \mapsto \lbrace \pi_{\mbox{7}} \rbrace $ \\
              $]$
            \end{tabular}
        \end{tabular}
      }
    \end{boxedminipage}
    \\
    (a) Example program.&
    \renewcommand{\arraystretch}{.9}{\begin{tabular}[t]{ll}
        (b) {\em e-path} to liveness environment map \\
        (c) Prog pt to {\em e-paths } map
    \end{tabular}}
  \end{tabular}
\end{picture}
\kern -3ex

\caption{Example Program and its liveness maps.}\label{fig:mot-example2}    
\end{figure*}

 For our example program which has  a
single function \length, this generates the following equations:

  \begin{eqnarray*}
    \Lf{\length}{1}{\sigma}
    &=& \epsilonset \cup \acdr\Lf{\length}{1}{\epsilon}
   \end{eqnarray*}

\subsection{Generating Liveness Equations for Function bodies}
For the running example, $\length$ has calls from $\mainpgm$ at $\pi_8$
and a recursive call at $\pi_6$.
\newcommand{\deltacall}[3]{\delta_{#1}({#2},{#3})}
So $\sigma_{\length} =
     \deltacall{\length}{\pi_8}{\mainpgm}  \cup \deltacall{\length}{\pi_6}{\length}$.
Filling in  the values gives:

\begin{align*}
\sigma_{\length}    &=
 \sigma_{\!all}  ~\cup~ \acdr\Lf{length}{1}{\sigma_{\mathit{\length}}}
\end{align*}

For the running example, containing unique GC points (corresponding to unique {\em e-paths} sets) $\pi_3, \pi_4, \pi_7$ in $\length$ and
$\pi_9$ in $e_\mainpgm$, this gives

\begin{align*}
\Lanv{7}{\xl} &= \acdr\Lf{\length}{1}{\epsilon} \cup \epsilonset \\
\Lanv{7}{\pu} &= \Lf{\length}{1}{\epsilon} \\
\Lanv{7}{\py} &= \epsilonset \\
\Lanv{3}{\xl} &= \epsilonset \\
\Lanv{3}{\px} &= \epsilonset 
\\[1ex]
  \Lanv{9}{\pb}  &= \Lf{\length}{1}{\sigma_{\mathit{\!all}}} \\
  \Lanv{9}{\pw}  &= \sigma_{\mathit{\!all}}
\end{align*}

\subsection{Solving liveness equations---the grammar interpretation}
The  equations above can now be re-interpreted as a
context-free grammar (CFG)  on the alphabet $\lbrace\acar, \acdr,
\bcar, \bcdr\rbrace$.  Let  \var{$X$} denote the non-terminal for
a variable  $X$ occurring on  the LHS of the  equations generated
from the analysis.  We can  think of the resulting productions as
being associated with several  grammars, one for each non-terminal
\var{\Lanv{i}{x}} regarded as a start symbol.  As an example, the
grammar    for   \var{\Lanv{7}{\xl}}   comprises    the   following
productions:
 \begin{eqnarray*}
\var{\Lanv{7}{\xl}}  &\rightarrow&   \var{\acdr \Lf
  {\length}{1}{\epsilon}} \mid \epsilon \\
\end{eqnarray*}

%}

% \item



\section{Implementation}
% GC assumptions
By the  time the program  starts executing, the liveness  automata are
created and stored in a file.   This is re-used every time the program
executes.
% GC points - mention reduction of gc points due to e-paths
An important  difference in GC of  lazy language compared  to an eager
language  is  the  point  of  garbage collection.  In  case  of  eager
languages only \CONS~ points and  function calls are the GC points. In
a lazy language  every \LET~ statement is a  potential GC point. Hence
we  need  to store  liveness  automata  corresponding  to every  \LET~
statement in the program. This leads  to an explosion in the number of
automata. From our observation that  along an {\em E-path} all program
points have  the same liveness, we  can reduce the  number of automata
state required  by sharing  the same automata  for all  program points
along an {\em E-path}. In the  example program, we only need to create
automata for program  points \ldots, since they are  the only distinct
{\em E-path}s in the program.
% Abstract description of the GC algorithm
\begin{algorithmic}
\STATE $new\_cell\gets$ dup\_heapcell(cell)
\IF{$celltype\ is\ cons\ and\ not(copied\_using\_rgc)$}
\STATE $new\_car\gets$ copy($cell.car$)
\STATE $new\_cell.car\gets$ $new\_car$ 
\STATE $new\_cdr\gets$ copy(cell.cdr)
\STATE $new\_cell.cdr\gets$ $new\_cdr$
\ELSE
\IF {$celltype\ is\ closure\ and\ cell\ not\ already\ copied$}
\STATE $new\_cell\gets$ dup\_heapcell(cell)
\STATE $new\_cell.arg1\gets$ copy($cell.arg1$)  
\STATE $new\_cell.arg2\gets$ copy($cell.arg2$)  
\ELSE
\STATE $new\_cell\gets$ dup\_heapcell(cell)
\ENDIF
\ENDIF
\end{algorithmic}

% Liveness for cons cells & reachability for closures
During GC, if the heap cell being processed is a cons cell, we consult
the  liveness automaton  corresponding to  it and  copy only  the live
paths.  In  case  the  heap  cell  points  to  a  closure,  we  safely
approximate the  liveness to be {\{0+1\}\*} and  copy everything under
the closure.
% Handling of mixture of LGC & RGC
A consequence of  copying everything under a closure  is the fact that
we can end up trying to copy things which are not live and corrupt the
heap. This  can happen if at some  $GC_k$ a cons cell  is copied using
liveness. At  a later stage this  cons cell becomes part  of a closure
and  hence during $GC_{k+n}$  the algorithm  tries to  copy everything
under the  cons cell  thus copying heap  locations which might  not be
valid.  To avoid  this behavior we either have to choose  to do a full
liveness based  GC for closure or  we should ensure  that any non-live
references are  not carried across  GC's. We take the  latter approach
and ensure that  non-live references are set to  null. After every GC,
the live part of the buffer  is scanned and any reference which is not
live is  set to null.  The correctness of  this follows from  the fact
that any reference which is decalred  not live in a $GC_k$ will not be
derefernced during later execution.
% A reference copied using LGC could become part of a closure in a later GC
% and copy wrong locations. Avoiding it by setting non-live references to null after every GC.
% Proof for the correctness. 
% Difference between eager and lazy GC


Another  difference that is  present in  GC of  lazy language  is the
presence  of  a print  stack.  In  lazy  languages the  evaluation  of
closures is  driven by the print  function.  Hence, during  a GC there
will be heap  references that will be present on  the stack which also
have  to  copied/collected.   One  solution  is  to  assume  that  all
references  present  on  the  print  stack are  fully  live  and  copy
everything pointed  by them  akin to reachability.   This is  safe but
copies heap  cells which  have already been  printed. Since  the print
function is  not part of  the executing program its  liveness automata
are not  considered. Therefore we  simulate the liveness of  the print
function by using a flag in  the heap cell. The flag ensures that only
the required parts  of a cons cell are copied. The  behavior of the GC
algorithm is as described below,
\begin{algorithmic}
\STATE $new\_cell\gets$ dup\_heapcell(cell)
\IF{$celltype\ is\ cons\ and\ not(processed\_car\_part)$}
\STATE $new\_cdr\gets$ copy(cell.cdr)
\STATE $new\_cell.cdr\gets$ $new\_cdr$
\ENDIF
\end{algorithmic}
We   provide   an   intuition    about   the   correctness   of   this
algorithm. Consider the following facts about the print stack during a
GC, 

\begin{enumerate}
\item The top of the stack always contains a reference to a closure.
\item All other references on the print stack point to atomic values or cons cells, it can never contain a
reference to a closure. The components of the cons cell can contain reference to closures.
\item If a reference on the print stack is a cons cell, either its car part or its cdr part will also be 
present on the stack.
\end{enumerate}
%Needs to be formatted and re-written
Sketch of the proof
Since all closures are copied fully and atomic values are copied, only cons cells need to be handled. 
Consider the following cases,
\begin{enumerate}
\item the car part of the cons  cell is on the print stack. This means
  that the GC happened while the car part was being processed. The cdr
  part is yet to be processed and the reference to the cdr part is not
  on the print stack. Hence it is sufficient to copy only the cdr part
  of the  cons cell. Any  references necessary for processing  the car
  part will be copied due to references on the print stack.
\item the cdr part of the cons  cell is on the print stack. This means
  that GC  happened while the cdr  part was being  processed.  The car
  part has already been processed and printed, hence we do not need to
  copy the car  part. Additionally any references that  are needed for
  printing the cdr  part will also be copied due  to the references on
  the print stack and hence nothing needs to be copied in this case.
\end{enumerate}
% Doing GC for  references on the print stack - using  a flag to avoid
% copying non-live  cells Optimizing  GC for closures  - use  a copied
% using rgc flag for closures to avoid multiple traversals
One of the  reasosn why reachability based GC  is faster than liveness
based GC is  due to the fact that  in case we try to copy  a cons cell
which is  already copied  we do  not need to  traverse it  any further
while doing RGC. The  same is not true in the case  of LGC, as the set
of  liveness paths  may not  be similar  in both  the  traversals. One
optimization is  to keep  track of all  the liveness  automaton states
that a particular  cons cell has been visited with  and ensure that we
do  not  traverse  it  with  the  same state  more  than  once.   This
optimization requires extra memory  for each heap cell and potentially
it can hold  all the automata states.  Therefore it  is not a feasible
solution. In case of lazy  languages since we use reachability to copy
closures, some cons  cells might be copied using  reachability. We can
avoid  repeated traversals of  these cons  cells without  tracking the
states. This only requires the  knowledge of whether the cons cell was
copied using  reachability.  Hence  we use a  flag to remember  if the
heap cell was  copied using reachability at any time, if  it is set we
do not traverse any further.

\section{Results}
%Add graphs for memort usage LGC vs RGC
%Add graphs/table showing the GC times and other statistics
\section{Conclusion and Future Work}
%Mention lower peak memory usage. 
%Mention faster GC than full LGC and more garbage collected than RGC.
%Pitch it as sweet spot between full LGC and RGC.
%Future work
%Mention full LGC
%Mention k-liveness, use length example to show 1-liveness is not sufficient.
%Mention mixed mode GC, 
% - doing RGC most of the times and switching to LGC in case RGC fails to collect any garbage
% - doing LGC most of the times but regularly checking the reachability of the heap and 
% switching to RGC if LGC almost equals RGC

\subsection{References}
\bibliography{fun_hra}{}
\bibliographystyle{abbrv}

Generated by bibtex from your ~.bib file.  Run latex,
then bibtex, then latex twice (to resolve references)
to create the ~.bbl file.  Insert that ~.bbl file into
the .tex source file and comment out
the command \texttt{{\char'134}thebibliography}.
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
\section{More Help for the Hardy}
The sig-alternate.cls file itself is chock-full of succinct
and helpful comments.  If you consider yourself a moderately
experienced to expert user of \LaTeX, you may find reading
it useful but please remember not to change it.
%\balancecolumns % GM June 2007
% That's all folks!

\end{document}


